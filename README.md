<h2> Safe Exploration Papers </h2>

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(1).pdf" style="text-decoration:none;">AI Safety Gridworlds</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(2).pdf" style="text-decoration:none;">Learning-based Model Predictive Control for Safe Exploration</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(3).pdf" style="text-decoration:none;">Safe Exploration for Optimizing Contextual Bandits</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(4).pdf" style="text-decoration:none;">Enforcing Almost-Sure Reachability in POMDPs</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(5).pdf" style="text-decoration:none;">Concrete Problems in AI Safety</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(6).pdf" style="text-decoration:none;">Safe Exploration in Continuous Action Spaces</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(7).pdf" style="text-decoration:none;">SafeML: Safety Monitoring of Machine Learning Classifiers through Statistical Difference Measure </a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(8).pdf" style="text-decoration:none;"> Safe Exploration in Finite Markov Decision Processes with Gaussian Processes </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Safe-Exploration-Papers/blob/master/se(9).pdf" style="text-decoration:none;">Verifiably Safe Exploration for End-to-End Reinforcement Learning</a></li>
  
   </ul>
